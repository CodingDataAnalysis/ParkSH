{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import itertools\n",
    "import platform\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager, rc\n",
    "import seaborn as sns\n",
    "%precision 3\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "#그래프를 주피터 놋북에 그리기 위해\n",
    "import numpy as np\n",
    "import copy\n",
    "from matplotlib import ticker\n",
    "from scipy.stats import probplot\n",
    "from scipy import stats\n",
    "import collections\n",
    "import itertools\n",
    "import math\n",
    "#from varname import nameof\n",
    "import sys\n",
    "from scipy import stats\n",
    "from scipy.stats import bernoulli\n",
    "import scipy\n",
    "from collections import deque\n",
    "from sympy import Symbol, solve\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "#히스토그램 그리기\n",
    "# Window\n",
    "if platform.system() == 'Windows':\n",
    "    matplotlib.rc('font', family='Malgun Gothic')\n",
    "elif platform.system() == 'Darwin': # Mac\n",
    "    matplotlib.rc('font', family='AppleGothic')\n",
    "else: #linux\n",
    "    matplotlib.rc('font', family='NanumGothic')\n",
    "\n",
    "# 그래프에 마이너스 표시가 되도록 변경\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 한글 폰트 설정\n",
    "font_location = 'C:/Windows/Fonts/MALGUNSL.TTF' #맑은고딕\n",
    "font_name = font_manager.FontProperties(fname=font_location).get_name()\n",
    "rc('font',family=font_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_path = '../titanic/'\n",
    "\n",
    "train = pd.read_csv(data_path + 'train.csv' , index_col = 'PassengerId')\n",
    "test = pd.read_csv(data_path + 'test.csv' , index_col = 'PassengerId')\n",
    "submission = pd.read_csv(data_path + 'gender_submission.csv' , index_col= 'PassengerId')\n",
    "\n",
    "origin_submission = pd.read_csv(data_path + 'gender_submission.csv' , index_col= 'PassengerId')\n",
    "\n",
    "all_data = pd.read_csv(data_path + 'all_data_5_22_17_10_42.csv' , index_col= 'PassengerId')\n",
    "\n",
    "\n",
    "correct = pd.read_csv(data_path + '정답.csv' , index_col= 'PassengerId')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "submission"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "all_data['log_Fare'] = np.log(all_data['Fare'])\n",
    "all_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_data['FareBin'] = pd.qcut(all_data['Fare'], 13)\n",
    "all_data['Fare_clean'] = all_data['FareBin'].astype('category').cat.codes\n",
    "all_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_data['Family'] = all_data['SibSp'] + all_data['Parch']\n",
    "\n",
    "all_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ax = sns.countplot(x='Family',  hue = 'Survival' , data = all_data)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ax = sns.countplot(x='Name',  hue = 'Survival' , data = all_data)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cabin 전처리 해보기"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_data['Cabin'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# LabelEncoder 객체 생성\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# 나이 열 변환\n",
    "all_data['Age_binned'] = label_encoder.fit_transform(all_data['Age_binned'])\n",
    "\n",
    "all_data['Survival'] = label_encoder.fit_transform(all_data['Survival'])\n",
    "all_data\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "#\n",
    "# encoder = OneHotEncoder() # 원-핫 인코더 생성\n",
    "#\n",
    "# all_data_encoded = encoder.fit_transform(all_data)\n",
    "#\n",
    "# all_data_encoded"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# num_train = len(train) # 훈련 데이터 개수\n",
    "#\n",
    "# # 훈련 데이터와 테스트 데이터 나누기\n",
    "#\n",
    "# X= all_data_encoded[:num_train] # 0~num_train -1 행\n",
    "# X_test = all_data_encoded[num_train:] # num_train ~ 마지막 행\n",
    "#\n",
    "# y = train['Survived'].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features2 = all_data.columns.tolist()\n",
    "features2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 서브플롯을 생성할 크기 설정\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# 피처들의 리스트\n",
    "features = features2\n",
    "\n",
    "# 피처들에 대한 countplot 그리기\n",
    "for i, feature in enumerate(features):\n",
    "    plt.subplot(4, 4, i+1)\n",
    "    sns.countplot(x=feature, hue='Survival', data=all_data)\n",
    "    plt.title(f'{feature} - Survived Countplot')\n",
    "\n",
    "# 레이아웃 조정\n",
    "plt.tight_layout()\n",
    "\n",
    "# 그래프 출력\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# 피처들의 리스트\n",
    "features = features\n",
    "\n",
    "# 각 피처별 'Survived'와의 상관계수 계산\n",
    "correlations = all_data[features + ['Survival']].corr()\n",
    "# filtered_correlations = correlations[correlations['Survival'].abs() >= 0.2]\n",
    "\n",
    "# 상관계수 히트맵 시각화\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlations, annot=True, cmap='RdYlBu')\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "\n",
    "# 그래프 출력\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "object_col = ['Name' , 'Sex' , 'Embarked'  ,'Age_binned', 'Fare_clean' ,  'Cabin'  ]\n",
    "binary_col = ['Fare' ,'Family', 'Pclass', 'log_Fare'  ]\n",
    "\n",
    "idx_col = ['Age_binned' , 'Fare_binned']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_data.columns.tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_data_2 = all_data[['Name' , 'Sex' , 'Embarked' , 'Age_binned' , 'Pclass', 'SibSp' , 'Parch', 'Cabin','Fare_clean'  ,'Family'  ]]\n",
    "\n",
    "all_data_2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 타깃값 분포"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def write_percent(ax , total_size):\n",
    "    '''도형 객체를 순회하며 막대 상단에 타깃값 비율 표시'''\n",
    "    for patch in ax.patches:\n",
    "        height = patch.get_height() # 도형 높이(데이터 개수)\n",
    "        width = patch.get_width() # 도형 너비\n",
    "        left_coord = patch.get_x() # 도형 왼쪽 테두리의 x축 위치\n",
    "        percent = height/total_size*100 # 타깃값 비율\n",
    "\n",
    "\n",
    "        # (x, y) 좌표에 텍스트 입력\n",
    "        ax.text(x= left_coord + width/2.0 ,   # x축 위치\n",
    "                y = height + total_size*0.001, #y축 위치\n",
    "                s = f'{percent : 1.1f}%', # 입력 텍스트\n",
    "                ha = 'center') #가운데 정렬\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 연속형 피처 분포"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 그래프 크기 설정\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# 그래프 그리기\n",
    "ax = sns.countplot(x='Fare_clean', hue='Survival', data=all_data)\n",
    "\n",
    "# x 축 값이 잘 보이도록 설정\n",
    "ax.tick_params(axis='x', labelrotation=45)\n",
    "\n",
    "# 그래프 출력\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 인코딩 및 스케일링 된 피처 합치기"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "all_data_2 = all_data_2.astype(np.float32)\n",
    "\n",
    "\n",
    "\n",
    "all_data_2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 로지스틱 회귀"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#\n",
    "num_train = len(train) # 훈련 데이터 개수\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 나누기\n",
    "\n",
    "X_train= all_data_2[:num_train] # 0~num_train -1 행\n",
    "X_test = all_data_2[num_train:] # num_train ~ 마지막 행\n",
    "\n",
    "y_train = train['Survived'].values\n",
    "\n",
    "\n",
    "# ########################################\n",
    "# # 데이터 분할\n",
    "# num_train = len(train) # 훈련 데이터 개수\n",
    "#\n",
    "# # 훈련 데이터와 테스트 데이터 나누기\n",
    "#\n",
    "# X= all_data_sprs[:num_train] # 0~num_train -1 행\n",
    "# X_test = all_data_sprs[num_train:] # num_train ~ 마지막 행\n",
    "#\n",
    "# y = train['Survived'].values\n",
    "#\n",
    "#\n",
    "# X_train , X_valid , y_train, y_valid = train_test_split(X,y, test_size = 0.2, random_state=0)\n",
    "y_test = correct['Survived'].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Logistic regression model creation\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "# Model training\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "# Accuracy evaluation\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# 현재 날짜와 시각 구하기\n",
    "now = datetime.datetime.now()\n",
    "date_list = [now.month, now.day, now.hour, now.minute, now.second]\n",
    "# 현재 날짜와 시각 출력하기\n",
    "print(\"현재 날짜 및 시각 : \", date_list)\n",
    "\n",
    "# 제출 파일 생성\n",
    "\n",
    "submission['Survived'] = y_pred\n",
    "submission.to_csv(f'submission_Logistic_{date_list[0]}_{date_list[1]}_{date_list[2]}_{date_list[3]}_{date_list[4]}.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#\n",
    "num_train = len(train) # 훈련 데이터 개수\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 나누기\n",
    "\n",
    "X_train= all_data_2[:num_train] # 0~num_train -1 행\n",
    "X_test = all_data_2[num_train:] # num_train ~ 마지막 행\n",
    "\n",
    "y_train = train['Survived'].values\n",
    "\n",
    "\n",
    "# ########################################\n",
    "# # 데이터 분할\n",
    "# num_train = len(train) # 훈련 데이터 개수\n",
    "#\n",
    "# # 훈련 데이터와 테스트 데이터 나누기\n",
    "#\n",
    "# X= all_data_sprs[:num_train] # 0~num_train -1 행\n",
    "# X_test = all_data_sprs[num_train:] # num_train ~ 마지막 행\n",
    "#\n",
    "# y = train['Survived'].values\n",
    "#\n",
    "#\n",
    "# X_train , X_valid , y_train, y_valid = train_test_split(X,y, test_size = 0.2, random_state=0)\n",
    "y_test = correct['Survived'].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 로지스틱 회귀 모델 생성\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "# 하이퍼파라미터 값 목록\n",
    "lr_params = {\n",
    "    'penalty': ['l1', 'l2'],                      # 규제 유형 ('l1': L1 규제, 'l2': L2 규제)\n",
    "    'C': [0.1, 1.0, 10.0],                        # 규제 강도의 역수 (값이 작을수록 강한 규제)\n",
    "    'solver': ['lbfgs', 'newton-cg', 'saga'],      # 최적화에 사용할 알고리즘\n",
    "    'max_iter': [50,100,150],                 # 최대 반복 횟수\n",
    "    'class_weight': [None, 'balanced'],            # 클래스 가중치 (None: 균등한 가중치, 'balanced': 불균등한 가중치)\n",
    "    'dual': [True, False],                         # 이중 문제 유형 (True: 이중 문제 사용, False: 원 문제 사용)\n",
    "    # 'fit_intercept': [True, False],                # 절편(intercept) 학습 여부\n",
    "    # 'intercept_scaling': [1, 2, 3],                # 절편의 스케일링 비율\n",
    "    # 'l1_ratio': [None, 0.2, 0.5],                  # L1 규제와 L2 규제 사이의 혼합 비율\n",
    "    # 'multi_class': ['auto', 'ovr', 'multinomial'], # 다중 클래스 처리 방법 ('auto': 자동 선택, 'ovr': 일대다, 'multinomial': 다항 분류)\n",
    "    'n_jobs': [None, -1],                          # 병렬 처리에 사용할 CPU 코어 수 (None: 1개, -1: 모든 코어)\n",
    "    'random_state': [42],                          # 난수 발생 시드 값\n",
    "    'tol': [0.0001, 0.001, 0.01],                  # 수렴 기준 (작을수록 더 정밀한 계산)\n",
    "    # 'verbose': [0, 1, 2],                          # 출력 메시지 레벨 (0: 출력 없음, 1: 진행 상황 메시지, 2: 모든 메시지)\n",
    "    # 'warm_start': [True, False]                    # 이전 학습 결과를 재사용하여 학습 계속 여부\n",
    "}\n",
    "\n",
    "# 그리드서치 객체 생성\n",
    "gridsearch_logistic_model = GridSearchCV(estimator=logistic_model,\n",
    "                                         param_grid=lr_params,\n",
    "                                         scoring='roc_auc',\n",
    "                                         cv=5)\n",
    "\n",
    "# 그리드서치 수행\n",
    "gridsearch_logistic_model.fit(X_train, y_train)\n",
    "print('최적 하이퍼파라미터:', gridsearch_logistic_model.best_params_)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_preds = gridsearch_logistic_model.predict(X_test)\n",
    "\n",
    "y_preds"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'Decsion Tree에 대한 점수 : {gridsearch_logistic_model.score(X_train , y_train)}')\n",
    "accuracy = accuracy_score(y_preds, y_test)\n",
    "print(\"Accuracy:\", accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# 테스트 데이터에 대한 예측 수행\n",
    "\n",
    "# 정확도 계산\n",
    "accuracy = accuracy_score(y_test, y_preds)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# 정밀도 계산\n",
    "precision = precision_score(y_test, y_preds)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# 재현율 계산\n",
    "recall = recall_score(y_test, y_preds)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# F1 스코어 계산\n",
    "f1 = f1_score(y_test, y_preds)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# ROC AUC 계산\n",
    "roc_auc = roc_auc_score(y_test, y_preds)\n",
    "print(\"ROC AUC Score:\", roc_auc)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# 분류 보고서 생성\n",
    "report = classification_report(y_test, y_preds)\n",
    "\n",
    "# 결과 출력\n",
    "print(report)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#\n",
    "# num_train = len(train) # 훈련 데이터 개수\n",
    "#\n",
    "# # 훈련 데이터와 테스트 데이터 나누기\n",
    "#\n",
    "# X_train= all_data_2[:num_train] # 0~num_train -1 행\n",
    "# X_test = all_data_2[num_train:] # num_train ~ 마지막 행\n",
    "#\n",
    "# y_train = train['Survived'].values\n",
    "\n",
    "\n",
    "# ########################################\n",
    "# # 데이터 분할\n",
    "num_train = len(train) # 훈련 데이터 개수\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 나누기\n",
    "\n",
    "X= all_data_2[:num_train] # 0~num_train -1 행\n",
    "X_test = all_data_2[num_train:] # num_train ~ 마지막 행\n",
    "\n",
    "y = train['Survived'].values\n",
    "\n",
    "\n",
    "X_train , X_valid , y_train, y_valid = train_test_split(X,y, test_size = 0.2, random_state=0)\n",
    "y_test = correct['Survived'].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'Decsion Tree에 대한 점수 : {gridsearch_logistic_model.score(X_valid , y_valid)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# 현재 날짜와 시각 구하기\n",
    "now = datetime.datetime.now()\n",
    "date_list = [now.month, now.day, now.hour, now.minute, now.second]\n",
    "# 현재 날짜와 시각 출력하기\n",
    "print(\"현재 날짜 및 시각 : \", date_list)\n",
    "\n",
    "# 제출 파일 생성\n",
    "\n",
    "submission['Survived'] = y_preds\n",
    "submission.to_csv(f'submission_DescisionTree_logistic_{date_list[0]}_{date_list[1]}_{date_list[2]}_{date_list[3]}_{date_list[4]}.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " 위의 코드는 이미 K-Fold 교차 검증을 적용하고 있습니다. GridSearchCV 함수의 cv 매개변수를 5로 설정하여 5-Fold 교차 검증을 수행하고 있습니다. cv 매개변수를 원하는 K 값으로 변경하여 다른 K-Fold 값에서 교차 검증을 수행할 수 있습니다.\n",
    "\n",
    "따라서, 위의 코드는 이미 K-Fold 교차 검증을 시행하고 있으며, 각 Fold에서의 최적 모델과 파라미터를 출력하고 있습니다."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#\n",
    "num_train = len(train) # 훈련 데이터 개수\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 나누기\n",
    "\n",
    "X_train= all_data_2[:num_train] # 0~num_train -1 행\n",
    "X_test = all_data_2[num_train:] # num_train ~ 마지막 행\n",
    "\n",
    "y_train = train['Survived'].values\n",
    "\n",
    "\n",
    "# ########################################\n",
    "# # 데이터 분할\n",
    "# num_train = len(train) # 훈련 데이터 개수\n",
    "#\n",
    "# # 훈련 데이터와 테스트 데이터 나누기\n",
    "#\n",
    "# X= all_data_sprs[:num_train] # 0~num_train -1 행\n",
    "# X_test = all_data_sprs[num_train:] # num_train ~ 마지막 행\n",
    "#\n",
    "# y = train['Survived'].values\n",
    "#\n",
    "#\n",
    "# X_train , X_valid , y_train, y_valid = train_test_split(X,y, test_size = 0.2, random_state=0)\n",
    "y_test = correct['Survived'].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_model = DecisionTreeClassifier()\n",
    "\n",
    "# 그리드 서치를 위한 하이퍼파라미터 그리드 준비\n",
    "param_grid = {\n",
    "    'max_depth': [2, 3, 5, 10],                        # 의사결정트리의 최대 깊이\n",
    "    'min_samples_split': [1, 2, 3, 5, 7, 10],            # 노드를 분할하기 위한 최소 샘플 수\n",
    "    'min_samples_leaf': [0, 1, 2, 3, 4, 5, 6],           # 리프 노드에 필요한 최소 샘플 수\n",
    "    'ccp_alpha': [0.0, 0.1, 0.2],                     # Cost-Complexity Pruning (CCP) 알고리즘에 대한 복잡성 매개변수\n",
    "    # 'class_weight': [None, 'balanced'],               # 클래스별 가중치 (None: 균등한 가중치, 'balanced': 불균등한 가중치)\n",
    "    'criterion': ['gini', 'entropy'],                  # 불순도(impurity) 계산에 사용할 기준 ('gini': Gini 불순도, 'entropy': 엔트로피)\n",
    "    # 'max_features': ['auto', 'sqrt', 'log2', None],    # 각 분할에서 고려할 최대 특성 개수 ('auto': sqrt(features), 'sqrt': sqrt(features), 'log2': log2(features), None: 모든 특성)\n",
    "    'max_leaf_nodes': [1, 5, 10, 15],               # 리프 노드의 최대 개수 (None: 제한 없음, 정수 값: 리프 노드의 최대 개수)\n",
    "    # 'min_impurity_decrease': [0.0, 0.1, 0.2],          # 분할 기준으로서 필요한 최소 불순도 감소량\n",
    "    # 'min_weight_fraction_leaf': [0.0, 0.1, 0.2],       # 리프 노드의 최소 가중치 비율\n",
    "    'random_state': [42],                              # 난수 발생 시드 값\n",
    "    'splitter': ['best', 'random']                     # 분할 기준을 선택하는 전략 ('best': 최적의 분할, 'random': 무작위 분할)\n",
    "}\n",
    "\n",
    "# 그리드 서치 객체 생성\n",
    "grid_search = GridSearchCV(dt_model, param_grid, cv=10, n_jobs=-1)\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 모델 및 파라미터 출력\n",
    "best_model_grid_search_dc = grid_search.best_estimator_\n",
    "best_params_grid_search_dc = grid_search.best_params_\n",
    "print(\"Best Model:\", best_model_grid_search_dc)\n",
    "print(\"Best Parameters:\", best_params_grid_search_dc)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_preds = best_model_grid_search_dc.predict(X_test)\n",
    "\n",
    "y_preds"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# 테스트 데이터에 대한 예측 수행\n",
    "\n",
    "# 정확도 계산\n",
    "accuracy = accuracy_score(y_test, y_preds)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# 정밀도 계산\n",
    "precision = precision_score(y_test, y_preds)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# 재현율 계산\n",
    "recall = recall_score(y_test, y_preds)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# F1 스코어 계산\n",
    "f1 = f1_score(y_test, y_preds)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# ROC AUC 계산\n",
    "roc_auc = roc_auc_score(y_test, y_preds)\n",
    "print(\"ROC AUC Score:\", roc_auc)\n",
    "\n",
    "print(f'Decsion Tree에 대한 점수 : {best_model_grid_search_dc.score(X_train , y_train)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# `y_preds`와 `submission`을 DataFrame으로 변환\n",
    "y_preds_df = pd.DataFrame(y_preds, columns=['Prediction'])\n",
    "submission_df = origin_submission.reset_index()\n",
    "\n",
    "# `y_preds_df`와 `submission_df`를 합치기\n",
    "compare = pd.concat([y_preds_df, submission_df], axis=1)\n",
    "compare = compare[['Prediction' , 'Survived']]\n",
    "compare['Compare'] = (compare['Prediction'] == compare['Survived'])\n",
    "compare['Compare'].value_counts()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#\n",
    "# num_train = len(train) # 훈련 데이터 개수\n",
    "#\n",
    "# # 훈련 데이터와 테스트 데이터 나누기\n",
    "#\n",
    "# X_train= all_data_sprs[:num_train] # 0~num_train -1 행\n",
    "# X_test = all_data_sprs[num_train:] # num_train ~ 마지막 행\n",
    "#\n",
    "# y_train = train['Survived'].values\n",
    "#\n",
    "#\n",
    "# ########################################\n",
    "# # 데이터 분할\n",
    "num_train = len(train) # 훈련 데이터 개수\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 나누기\n",
    "\n",
    "X= all_data_2[:num_train] # 0~num_train -1 행\n",
    "X_test = all_data_2[num_train:] # num_train ~ 마지막 행\n",
    "\n",
    "y = train['Survived'].values\n",
    "\n",
    "\n",
    "X_train , X_valid , y_train, y_valid = train_test_split(X,y, test_size = 0.2, random_state=0)\n",
    "y_test = correct['Survived'].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'Decsion Tree에 대한 점수 : {best_model_grid_search_dc.score(X_valid , y_valid)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n",
    "fig = plt.figure(figsize =  (30,15)) # 그래프 크기 설정\n",
    "\n",
    "ax =plot_tree(best_model_grid_search_dc, max_depth=5, fontsize=15)\n",
    "# 트리 그래프 출력\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# 현재 날짜와 시각 구하기\n",
    "now = datetime.datetime.now()\n",
    "date_list = [now.month, now.day, now.hour, now.minute, now.second]\n",
    "# 현재 날짜와 시각 출력하기\n",
    "print(\"현재 날짜 및 시각 : \", date_list)\n",
    "\n",
    "# 제출 파일 생성\n",
    "\n",
    "submission['Survived'] = y_preds\n",
    "submission.to_csv(f'submission_gridsearch_DescisionTree_{date_list[0]}_{date_list[1]}_{date_list[2]}_{date_list[3]}_{date_list[4]}.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LightGBM 모델"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#\n",
    "num_train = len(train) # 훈련 데이터 개수\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 나누기\n",
    "\n",
    "X_train= all_data_2[:num_train] # 0~num_train -1 행\n",
    "X_test = all_data_2[num_train:] # num_train ~ 마지막 행\n",
    "\n",
    "y_train = train['Survived'].values\n",
    "\n",
    "\n",
    "# ########################################\n",
    "# # 데이터 분할\n",
    "# num_train = len(train) # 훈련 데이터 개수\n",
    "#\n",
    "# # 훈련 데이터와 테스트 데이터 나누기\n",
    "#\n",
    "# X= all_data_sprs[:num_train] # 0~num_train -1 행\n",
    "# X_test = all_data_sprs[num_train:] # num_train ~ 마지막 행\n",
    "#\n",
    "# y = train['Survived'].values\n",
    "#\n",
    "#\n",
    "# X_train , X_valid , y_train, y_valid = train_test_split(X,y, test_size = 0.2, random_state=0)\n",
    "y_test = correct['Survived'].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "LogisticRegression 모델은 LogisticRegression 클래스의 생성자에서 매개변수를 지정할 수 있는데, 이 클래스는 유효하지 않은 매개변수가 입력되면 ValueError를 발생시킵니다.\n",
    "\n",
    "반면에 LightGBM 모델은 LGBMClassifier 클래스의 생성자에서 매개변수를 지정하는데, 이 클래스는 유효하지 않은 매개변수를 무시하고 넘어가는 동작을 합니다. 따라서 LightGBM 모델에서는 유효하지 않은 매개변수가 입력되어도 그리드 서치 수행에 영향을 주지 않고 다른 유효한 매개변수들에 대해서만 최적의 모델을 탐색하게 됩니다.\n",
    "\n",
    "이러한 동작 차이 때문에 LogisticRegression 모델에서는 유효하지 않은 매개변수를 입력하면 에러가 발생하지만, LightGBM 모델에서는 무시되고 다른 매개변수들에 대해서만 그리드 서치가 수행됩니다."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "# LightGBM 모델 생성\n",
    "lgb_model = lgb.LGBMClassifier()\n",
    "\n",
    "# 그리드 서치를 위한 하이퍼파라미터 그리드 준비\n",
    "param_grid_lgb = {\n",
    "    'max_depth': [3, 4],                        # 트리의 최대 깊이\n",
    "    'learning_rate': [0.01, 0.05],               # 학습률\n",
    "    'n_estimators': [200, 300, 400],             # 트리의 개수\n",
    "    'min_child_samples': [1, 2, 3, 4],           # 리프 노드에 필요한 최소 샘플 수\n",
    "    'subsample': [0.05, 0.01],                   # 트리를 학습할 때 사용할 샘플링 비율\n",
    "    'colsample_bytree': [0.8,0.9, 1],                # 트리를 학습할 때 사용할 특성의 비율\n",
    "    'reg_alpha': [0.1,0.2],                     # L1 정규화 항의 가중치\n",
    "    'reg_lambda': [0.0, 0.1],                         # L2 정규화 항의 가중치\n",
    "    'ManchesterUNITED': [2, 3]                   # 유효하지 않은 매개변수 (무시됨)\n",
    "}\n",
    "\n",
    "# 그리드 서치 객체 생성\n",
    "grid_search_lgb = GridSearchCV(lgb_model, param_grid_lgb, cv=10, n_jobs=-1)\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search_lgb.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 모델 및 파라미터 출력\n",
    "best_model_grid_search_lgb = grid_search_lgb.best_estimator_\n",
    "best_params_grid_search_lgb = grid_search_lgb.best_params_\n",
    "print(\"Best Model (LightGBM):\", best_model_grid_search_lgb)\n",
    "print(\"Best Parameters (LightGBM):\", best_params_grid_search_lgb)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_preds = best_model_grid_search_lgb.predict(X_test)\n",
    "\n",
    "y_preds"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# 테스트 데이터에 대한 예측 수행\n",
    "\n",
    "# 정확도 계산\n",
    "accuracy = accuracy_score(y_test, y_preds)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# 정밀도 계산\n",
    "precision = precision_score(y_test, y_preds)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# 재현율 계산\n",
    "recall = recall_score(y_test, y_preds)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# F1 스코어 계산\n",
    "f1 = f1_score(y_test, y_preds)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# ROC AUC 계산\n",
    "roc_auc = roc_auc_score(y_test, y_preds)\n",
    "print(\"ROC AUC Score:\", roc_auc)\n",
    "\n",
    "\n",
    "print(f'Decsion Tree에 대한 점수 : {best_model_grid_search_lgb.score(X_train , y_train)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#\n",
    "# num_train = len(train) # 훈련 데이터 개수\n",
    "#\n",
    "# # 훈련 데이터와 테스트 데이터 나누기\n",
    "#\n",
    "# X_train= all_data_sprs[:num_train] # 0~num_train -1 행\n",
    "# X_test = all_data_sprs[num_train:] # num_train ~ 마지막 행\n",
    "#\n",
    "# y_train = train['Survived'].values\n",
    "\n",
    "\n",
    "# ########################################\n",
    "# # 데이터 분할\n",
    "num_train = len(train) # 훈련 데이터 개수\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 나누기\n",
    "\n",
    "X= all_data_2[:num_train] # 0~num_train -1 행\n",
    "X_test = all_data_2[num_train:] # num_train ~ 마지막 행\n",
    "\n",
    "y = train['Survived'].values\n",
    "\n",
    "\n",
    "X_train , X_valid , y_train, y_valid = train_test_split(X,y, test_size = 0.2, random_state=0)\n",
    "y_test = correct['Survived'].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'Decsion Tree에 대한 점수 : {best_model_grid_search_lgb.score(X_valid , y_valid)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# 현재 날짜와 시각 구하기\n",
    "now = datetime.datetime.now()\n",
    "date_list = [now.month, now.day, now.hour, now.minute, now.second]\n",
    "# 현재 날짜와 시각 출력하기\n",
    "print(\"현재 날짜 및 시각 : \", date_list)\n",
    "\n",
    "# 제출 파일 생성\n",
    "\n",
    "submission['Survived'] = y_preds\n",
    "submission.to_csv(f'submission_DescisionTree_lgb_{date_list[0]}_{date_list[1]}_{date_list[2]}_{date_list[3]}_{date_list[4]}.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## XGBoost"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#\n",
    "num_train = len(train) # 훈련 데이터 개수\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 나누기\n",
    "\n",
    "X_train= all_data_2[:num_train] # 0~num_train -1 행\n",
    "X_test = all_data_2[num_train:] # num_train ~ 마지막 행\n",
    "\n",
    "y_train = train['Survived'].values\n",
    "\n",
    "\n",
    "# ########################################\n",
    "# # 데이터 분할\n",
    "# num_train = len(train) # 훈련 데이터 개수\n",
    "#\n",
    "# # 훈련 데이터와 테스트 데이터 나누기\n",
    "#\n",
    "# X= all_data_sprs[:num_train] # 0~num_train -1 행\n",
    "# X_test = all_data_sprs[num_train:] # num_train ~ 마지막 행\n",
    "#\n",
    "# y = train['Survived'].values\n",
    "#\n",
    "#\n",
    "# X_train , X_valid , y_train, y_valid = train_test_split(X,y, test_size = 0.2, random_state=0)\n",
    "# y_test = submission['Survived'].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "\n",
    "# XGBoost 모델 생성\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "\n",
    "# 그리드 서치를 위한 하이퍼파라미터 그리드 준비\n",
    "param_grid_xgb = {\n",
    "    # 'max_depth': [3, 5],\n",
    "    # 'learning_rate': [0.01 , 0.05],\n",
    "    # 'n_estimators': [300, 400],\n",
    "    # 'subsample': [1.0 ],  # subsample 비율\n",
    "    # 'colsample_bytree': [0.8, 0.9 ],  # 각 트리에 사용되는 특성(feature)의 비율\n",
    "    # 'gamma': [0 , 0.1],  # 트리 노드를 추가로 분할하기 위한 최소 손실 감소값\n",
    "    # 'reg_alpha': [0.01 ],  # L1 정규화 항의 가중치\n",
    "    # 'reg_lambda': [0]  # L2 정규화 항의 가중치\n",
    "    \"n_estimators\":[200 , 300],\n",
    "    \"max_depth\":[3,4,5],\n",
    "    \"learning_rate\":[.01,.1,.2],\n",
    "    \"subsample\":[.8 , 1.0],\n",
    "    \"colsample_bytree\":[0.8,1],\n",
    "    \"gamma\":[0,0.1,1,5],\n",
    "    \"lambda\":[.01,.1,1],\n",
    "    \"ManchesterUTD\" : [0, 0.2]\n",
    "\n",
    "}\n",
    "\n",
    "# 그리드 서치 객체 생성\n",
    "grid_search_xgb = GridSearchCV(xgb_model, param_grid_xgb, cv=10, n_jobs=-1)\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 모델 및 파라미터 출력\n",
    "best_model_grid_search_xgb = grid_search_xgb.best_estimator_\n",
    "best_params_grid_search_xgb = grid_search_xgb.best_params_\n",
    "print(\"Best Model (XGBoost):\", best_model_grid_search_xgb)\n",
    "print(\"Best Parameters (XGBoost):\", best_params_grid_search_xgb)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_preds = best_model_grid_search_xgb.predict(X_test)\n",
    "\n",
    "y_preds"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# 테스트 데이터에 대한 예측 수행\n",
    "\n",
    "# 정확도 계산\n",
    "accuracy = accuracy_score(y_test, y_preds)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# 정밀도 계산\n",
    "precision = precision_score(y_test, y_preds)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# 재현율 계산\n",
    "recall = recall_score(y_test, y_preds)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# F1 스코어 계산\n",
    "f1 = f1_score(y_test, y_preds)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# ROC AUC 계산\n",
    "roc_auc = roc_auc_score(y_test, y_preds)\n",
    "print(\"ROC AUC Score:\", roc_auc)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'Decsion Tree에 대한 점수 : {best_model_grid_search_xgb.score(X_train , y_train)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#\n",
    "# num_train = len(train) # 훈련 데이터 개수\n",
    "#\n",
    "# # 훈련 데이터와 테스트 데이터 나누기\n",
    "#\n",
    "# X_train= all_data_sprs[:num_train] # 0~num_train -1 행\n",
    "# X_test = all_data_sprs[num_train:] # num_train ~ 마지막 행\n",
    "#\n",
    "# y_train = train['Survived'].values\n",
    "\n",
    "\n",
    "# ########################################\n",
    "# # 데이터 분할\n",
    "num_train = len(train) # 훈련 데이터 개수\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 나누기\n",
    "\n",
    "X= all_data_2[:num_train] # 0~num_train -1 행\n",
    "X_test = all_data_2[num_train:] # num_train ~ 마지막 행\n",
    "\n",
    "y = train['Survived'].values\n",
    "\n",
    "\n",
    "X_train , X_valid , y_train, y_valid = train_test_split(X,y, test_size = 0.2, random_state=0)\n",
    "y_test = correct['Survived'].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'Decsion Tree에 대한 점수 : {best_model_grid_search_xgb.score(X_valid , y_valid)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# 현재 날짜와 시각 구하기\n",
    "now = datetime.datetime.now()\n",
    "date_list = [now.month, now.day, now.hour, now.minute, now.second]\n",
    "# 현재 날짜와 시각 출력하기\n",
    "print(\"현재 날짜 및 시각 : \", date_list)\n",
    "\n",
    "# 제출 파일 생성\n",
    "\n",
    "submission['Survived'] = y_preds\n",
    "submission.to_csv(f'submission_DescisionTree_xgb_{date_list[0]}_{date_list[1]}_{date_list[2]}_{date_list[3]}_{date_list[4]}.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RandomForest"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#\n",
    "num_train = len(train) # 훈련 데이터 개수\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 나누기\n",
    "\n",
    "X_train= all_data_2[:num_train] # 0~num_train -1 행\n",
    "X_test = all_data_2[num_train:] # num_train ~ 마지막 행\n",
    "\n",
    "y_train = train['Survived'].values\n",
    "\n",
    "\n",
    "# ########################################\n",
    "# # 데이터 분할\n",
    "# num_train = len(train) # 훈련 데이터 개수\n",
    "#\n",
    "# # 훈련 데이터와 테스트 데이터 나누기\n",
    "#\n",
    "# X= all_data_sprs[:num_train] # 0~num_train -1 행\n",
    "# X_test = all_data_sprs[num_train:] # num_train ~ 마지막 행\n",
    "#\n",
    "# y = train['Survived'].values\n",
    "#\n",
    "#\n",
    "# X_train , X_valid , y_train, y_valid = train_test_split(X,y, test_size = 0.2, random_state=0)\n",
    "# y_test = submission['Survived'].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Random Forest 모델 생성\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# 그리드 서치를 위한 하이퍼파라미터 그리드 준비\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],                   # 트리의 개수\n",
    "    'max_depth': [None, 5, 10],                        # 트리의 최대 깊이\n",
    "    'min_samples_split': [2, 5, 10],                    # 노드를 분할하기 위한 최소 샘플 수\n",
    "    'min_samples_leaf': [1, 2, 4],                      # 리프 노드에 필요한 최소 샘플 수\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],           # 각 분할에서 고려할 최대 특성 개수\n",
    "    # 'max_leaf_nodes': [None, 5, 10],                    # 리프 노드의 최대 개수\n",
    "    'min_impurity_decrease': [0.0, 0.1, 0.2],           # 분할 기준으로서 필요한 최소 불순도 감소량\n",
    "    'min_weight_fraction_leaf': [0.0, 0.1, 0.2],        # 리프 노드의 최소 가중치 비율\n",
    "    'n_jobs': [-1],                                     # 병렬로 수행할 작업 수 (-1: 모든 가능한 프로세서 사용)\n",
    "    'random_state': [42],                               # 난수 발생 시드 값\n",
    "    # 'class_weight': [None, 'balanced'],                 # 클래스별 가중치\n",
    "    'criterion': ['gini', 'entropy'],                    # 불순도 기준\n",
    "    'ccp_alpha': [0.0, 0.1, 0.2],                        # Cost-Complexity Pruning (CCP) 알고리즘에 대한 복잡성 매개변수\n",
    "\n",
    "    #'bootstrap': [True, False],                          # 부트스트래핑 여부\n",
    "    'oob_score': [True, False],                          # Out-of-Bag 평가 사용 여부\n",
    "    #'verbose': [0, 1, 2],                                # 학습 과정 중 출력 메시지 정도\n",
    "    # 'warm_start': [True, False]                          # 이전 호출의 솔루션을 재사용하여 학습 계속 여부\n",
    "}\n",
    "\n",
    "# 그리드 서치 객체 생성\n",
    "grid_search_rf = GridSearchCV(rf_model, param_grid_rf, cv=10, n_jobs=-1)\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 모델 및 파라미터 출력\n",
    "best_model_grid_search_rf = grid_search_rf.best_estimator_\n",
    "best_params_grid_search_rf = grid_search_rf.best_params_\n",
    "print(\"Best Model (Random Forest):\", best_model_grid_search_rf)\n",
    "print(\"Best Parameters (Random Forest):\", best_params_grid_search_rf)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_preds = best_model_grid_search_rf.predict(X_test)\n",
    "\n",
    "y_preds"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# `y_preds`와 `submission`을 DataFrame으로 변환\n",
    "y_preds_df = pd.DataFrame(y_preds, columns=['Prediction'])\n",
    "submission_df = origin_submission.reset_index()\n",
    "\n",
    "# `y_preds_df`와 `submission_df`를 합치기\n",
    "compare = pd.concat([y_preds_df, submission_df], axis=1)\n",
    "compare = compare[['Prediction' , 'Survived']]\n",
    "compare['Compare'] = (compare['Prediction'] == compare['Survived'])\n",
    "compare['Compare'].value_counts()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# 테스트 데이터에 대한 예측 수행\n",
    "\n",
    "# 정확도 계산\n",
    "accuracy = accuracy_score(y_test, y_preds)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# 정밀도 계산\n",
    "precision = precision_score(y_test, y_preds)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# 재현율 계산\n",
    "recall = recall_score(y_test, y_preds)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# F1 스코어 계산\n",
    "f1 = f1_score(y_test, y_preds)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# ROC AUC 계산\n",
    "roc_auc = roc_auc_score(y_test, y_preds)\n",
    "print(\"ROC AUC Score:\", roc_auc)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'Decsion Tree에 대한 점수 : {best_model_grid_search_rf.score(X_train , y_train)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#\n",
    "# num_train = len(train) # 훈련 데이터 개수\n",
    "#\n",
    "# # 훈련 데이터와 테스트 데이터 나누기\n",
    "#\n",
    "# X_train= all_data_sprs[:num_train] # 0~num_train -1 행\n",
    "# X_test = all_data_sprs[num_train:] # num_train ~ 마지막 행\n",
    "#\n",
    "# y_train = train['Survived'].values\n",
    "\n",
    "\n",
    "# ########################################\n",
    "# # 데이터 분할\n",
    "num_train = len(train) # 훈련 데이터 개수\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 나누기\n",
    "\n",
    "X= all_data_2[:num_train] # 0~num_train -1 행\n",
    "X_test = all_data_2[num_train:] # num_train ~ 마지막 행\n",
    "\n",
    "y = train['Survived'].values\n",
    "\n",
    "\n",
    "X_train , X_valid , y_train, y_valid = train_test_split(X,y, test_size = 0.2, random_state=0)\n",
    "y_test = correct['Survived'].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'Decsion Tree에 대한 점수 : {best_model_grid_search_rf.score(X_valid , y_valid)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# 현재 날짜와 시각 구하기\n",
    "now = datetime.datetime.now()\n",
    "date_list = [now.month, now.day, now.hour, now.minute, now.second]\n",
    "# 현재 날짜와 시각 출력하기\n",
    "print(\"현재 날짜 및 시각 : \", date_list)\n",
    "\n",
    "# 제출 파일 생성\n",
    "\n",
    "submission['Survived'] = y_preds\n",
    "submission.to_csv(f'submission_DescisionTree_rf_{date_list[0]}_{date_list[1]}_{date_list[2]}_{date_list[3]}_{date_list[4]}.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 앙상블 학습"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#\n",
    "num_train = len(train) # 훈련 데이터 개수\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 나누기\n",
    "\n",
    "X_train= all_data_2[:num_train] # 0~num_train -1 행\n",
    "X_test = all_data_2[num_train:] # num_train ~ 마지막 행\n",
    "\n",
    "y_train = train['Survived'].values\n",
    "\n",
    "\n",
    "# ########################################\n",
    "# # 데이터 분할\n",
    "# num_train = len(train) # 훈련 데이터 개수\n",
    "#\n",
    "# # 훈련 데이터와 테스트 데이터 나누기\n",
    "#\n",
    "# X= all_data_sprs[:num_train] # 0~num_train -1 행\n",
    "# X_test = all_data_sprs[num_train:] # num_train ~ 마지막 행\n",
    "#\n",
    "# y = train['Survived'].values\n",
    "#\n",
    "#\n",
    "# X_train , X_valid , y_train, y_valid = train_test_split(X,y, test_size = 0.2, random_state=0)\n",
    "# y_test = submission['Survived'].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# 최적의 모델들 생성\n",
    "best_model_log = gridsearch_logistic_model\n",
    "best_model_dc_Tree = grid_search.best_estimator_\n",
    "# best_model_rf = grid_search_rf.best_estimator_\n",
    "best_model_xgb = grid_search_xgb.best_estimator_\n",
    "best_model_lgb = grid_search_lgb.best_estimator_\n",
    "\n",
    "# 앙상블 모델 생성\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimators=[('log', best_model_log),('dcT', best_model_dc_Tree),\n",
    "                #('rf', best_model_rf),\n",
    "                ('xgb', best_model_xgb), ('lgb', best_model_lgb)],\n",
    "    voting='soft'  # 소프트 보팅 방식 사용 (확률 기반)\n",
    ")\n",
    "\n",
    "# 앙상블 모델 훈련\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "# 앙상블 모델 예측\n",
    "ensemble_predictions = ensemble_model.predict(X_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_preds = ensemble_predictions\n",
    "\n",
    "y_preds"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(ensemble_model.score(X_train, y_train))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#\n",
    "# num_train = len(train) # 훈련 데이터 개수\n",
    "#\n",
    "# # 훈련 데이터와 테스트 데이터 나누기\n",
    "#\n",
    "# X_train= all_data_sprs[:num_train] # 0~num_train -1 행\n",
    "# X_test = all_data_sprs[num_train:] # num_train ~ 마지막 행\n",
    "#\n",
    "# y_train = train['Survived'].values\n",
    "\n",
    "\n",
    "# ########################################\n",
    "# # 데이터 분할\n",
    "num_train = len(train) # 훈련 데이터 개수\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 나누기\n",
    "\n",
    "X= all_data_sprs[:num_train] # 0~num_train -1 행\n",
    "X_test = all_data_sprs[num_train:] # num_train ~ 마지막 행\n",
    "\n",
    "y = train['Survived'].values\n",
    "\n",
    "\n",
    "X_train , X_valid , y_train, y_valid = train_test_split(X,y, test_size = 0.2, random_state=0)\n",
    "y_test = correct['Survived'].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(ensemble_model.score(X_valid , y_valid))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# 현재 날짜와 시각 구하기\n",
    "now = datetime.datetime.now()\n",
    "date_list = [now.month, now.day, now.hour, now.minute, now.second]\n",
    "# 현재 날짜와 시각 출력하기\n",
    "print(\"현재 날짜 및 시각 : \", date_list)\n",
    "\n",
    "# 제출 파일 생성\n",
    "\n",
    "submission['Survived'] = y_preds\n",
    "submission.to_csv(f'submission_ensemble_{date_list[0]}_{date_list[1]}_{date_list[2]}_{date_list[3]}_{date_list[4]}.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#\n",
    "num_train = len(train) # 훈련 데이터 개수\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 나누기\n",
    "\n",
    "X_train= all_data_sprs[:num_train] # 0~num_train -1 행\n",
    "X_test = all_data_sprs[num_train:] # num_train ~ 마지막 행\n",
    "\n",
    "y_train = train['Survived'].values\n",
    "\n",
    "\n",
    "# ########################################\n",
    "# # 데이터 분할\n",
    "# num_train = len(train) # 훈련 데이터 개수\n",
    "#\n",
    "# # 훈련 데이터와 테스트 데이터 나누기\n",
    "#\n",
    "# X= all_data_sprs[:num_train] # 0~num_train -1 행\n",
    "# X_test = all_data_sprs[num_train:] # num_train ~ 마지막 행\n",
    "#\n",
    "# y = train['Survived'].values\n",
    "#\n",
    "#\n",
    "# X_train , X_valid , y_train, y_valid = train_test_split(X,y, test_size = 0.2, random_state=0)\n",
    "# y_test = submission['Survived'].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 모델들의 예측 결과 가져오기\n",
    "pred_logistic = gridsearch_logistic_model.predict(X_test)\n",
    "pred_dc = best_model_grid_search_dc.predict(X_test)\n",
    "pred_rf = best_model_grid_search_rf.predict(X_test)\n",
    "pred_xgb = best_model_grid_search_xgb.predict(X_test)\n",
    "pred_lgb = best_model_grid_search_lgb.predict(X_test)\n",
    "\n",
    "# 예측 결과를 numpy 배열로 변환\n",
    "preds = np.array([pred_logistic, pred_dc, pred_rf, pred_xgb, pred_lgb])\n",
    "\n",
    "# 상관 계수 계산\n",
    "correlation_matrix = np.corrcoef(preds)\n",
    "\n",
    "print(\"Correlation Matrix:\")\n",
    "print(correlation_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 앙상블 다시 개별 학습"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 개별 모델 생성\n",
    "model_logistic = LogisticRegression()\n",
    "model_dc_tree = DecisionTreeClassifier()\n",
    "model_rf = RandomForestClassifier()\n",
    "model_xgb = xgb.XGBClassifier()\n",
    "model_lgb = lgb.LGBMClassifier()\n",
    "\n",
    "# 개별 모델의 하이퍼파라미터 그리드 준비\n",
    "param_grid_logistic = {'C': [0.1, 0.5, 1.0], 'max_iter': [100, 200, 500]}\n",
    "param_grid_dc_tree = {'max_depth': [3, 5, 7], 'min_samples_split': [2, 5, 10]}\n",
    "param_grid_rf = {'n_estimators': [100, 200, 500], 'max_depth': [None, 5, 10]}\n",
    "param_grid_xgb = {'max_depth': [3, 5, 7], 'learning_rate': [0.1, 0.01, 0.001]}\n",
    "param_grid_lgb = {'max_depth': [3, 5, 7], 'learning_rate': [0.1, 0.01, 0.001]}\n",
    "\n",
    "# 개별 모델의 그리드 서치 객체 생성\n",
    "grid_search_logistic = GridSearchCV(model_logistic, param_grid_logistic, cv=5)\n",
    "grid_search_dc_tree = GridSearchCV(model_dc_tree, param_grid_dc_tree, cv=5)\n",
    "grid_search_rf = GridSearchCV(model_rf, param_grid_rf, cv=5)\n",
    "grid_search_xgb = GridSearchCV(model_xgb, param_grid_xgb, cv=5)\n",
    "grid_search_lgb = GridSearchCV(model_lgb, param_grid_lgb, cv=5)\n",
    "\n",
    "# 개별 모델의 그리드 서치 수행\n",
    "grid_search_logistic.fit(X_train, y_train)\n",
    "grid_search_dc_tree.fit(X_train, y_train)\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "grid_search_xgb.fit(X_train, y_train)\n",
    "grid_search_lgb.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 개별 모델 및 파라미터 출력\n",
    "best_model_logistic = grid_search_logistic.best_estimator_\n",
    "best_model_dc_tree = grid_search_dc_tree.best_estimator_\n",
    "best_model_rf = grid_search_rf.best_estimator_\n",
    "best_model_xgb = grid_search_xgb.best_estimator_\n",
    "best_model_lgb = grid_search_lgb.best_estimator_\n",
    "\n",
    "# 앙상블 모델 생성\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('log', best_model_logistic),\n",
    "        ('dcT', best_model_dc_tree),\n",
    "        ('rf', best_model_rf),\n",
    "        ('xgb', best_model_xgb),\n",
    "        ('lgb', best_model_lgb)\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# 앙상블 모델 훈련\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "# 앙상블 모델 예측\n",
    "ensemble_predictions = ensemble_model.predict(X_test)\n",
    "print(ensemble_model.score(X_train, y_train))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_preds = ensemble_predictions\n",
    "\n",
    "y_preds"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# 현재 날짜와 시각 구하기\n",
    "now = datetime.datetime.now()\n",
    "date_list = [now.month, now.day, now.hour, now.minute, now.second]\n",
    "# 현재 날짜와 시각 출력하기\n",
    "print(\"현재 날짜 및 시각 : \", date_list)\n",
    "\n",
    "# 제출 파일 생성\n",
    "\n",
    "submission['Survived'] = y_preds\n",
    "submission.to_csv(f'submission_ensemble2_{date_list[0]}_{date_list[1]}_{date_list[2]}_{date_list[3]}_{date_list[4]}.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 블로그 따라잡기"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_data_2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_data['Family'] = 1 + all_data['SibSp'] + all_data['Parch']\n",
    "\n",
    "all_data['Solo'] = (all_data['Family'] ==1)\n",
    "\n",
    "all_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_data['Name'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "feature = [\n",
    "    'Pclass',\n",
    "    'Sex',\n",
    "    'SibSp',\n",
    "    'Parch',\n",
    "    'Embarked',\n",
    "    'Family',\n",
    "    'Name',\n",
    "    'Solo',\n",
    "    'Age_binned',\n",
    "    'Cabin',\n",
    "    'Fare_clean'\n",
    "]\n",
    "\n",
    "label = [\n",
    "    'Survived',\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#\n",
    "num_train = len(train) # 훈련 데이터 개수\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 나누기\n",
    "\n",
    "X_train= all_data[:num_train] # 0~num_train -1 행\n",
    "X_test = all_data[num_train:] # num_train ~ 마지막 행\n",
    "\n",
    "y_train = train['Survived'].values\n",
    "\n",
    "\n",
    "# ########################################\n",
    "# # 데이터 분할\n",
    "# num_train = len(train) # 훈련 데이터 개수\n",
    "#\n",
    "# # 훈련 데이터와 테스트 데이터 나누기\n",
    "#\n",
    "# X= all_data_sprs[:num_train] # 0~num_train -1 행\n",
    "# X_test = all_data_sprs[num_train:] # num_train ~ 마지막 행\n",
    "#\n",
    "# y = train['Survived'].values\n",
    "#\n",
    "#\n",
    "# X_train , X_valid , y_train, y_valid = train_test_split(X,y, test_size = 0.2, random_state=0)\n",
    "# y_test = submission['Survived'].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train = X_train[feature]\n",
    "target = train[label]\n",
    "\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=50, max_depth=6, random_state=0)\n",
    "cross_val_score(clf, X_train, target, cv=k_fold, scoring='accuracy', ).mean()\n",
    "# Accuracy\n",
    "# 0.8271660424469414"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train = X_train[feature]\n",
    "x_test = X_test[feature]\n",
    "y_train = train[label]\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=50, max_depth=6, random_state=0)\n",
    "clf.fit(x_train, y_train)\n",
    "y_preds = clf.predict(x_test)\n",
    "\n",
    "y_preds"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# 현재 날짜와 시각 구하기\n",
    "now = datetime.datetime.now()\n",
    "date_list = [now.month, now.day, now.hour, now.minute, now.second]\n",
    "# 현재 날짜와 시각 출력하기\n",
    "print(\"현재 날짜 및 시각 : \", date_list)\n",
    "\n",
    "# 제출 파일 생성\n",
    "\n",
    "submission['Survived'] = y_preds\n",
    "submission.to_csv(f'submission_Random_blog_{date_list[0]}_{date_list[1]}_{date_list[2]}_{date_list[3]}_{date_list[4]}.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_data['Survival'] = label_encoder.fit_transform(all_data['Survival'])\n",
    "\n",
    "all_data['Survival']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#\n",
    "num_train = len(train) # 훈련 데이터 개수\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 나누기\n",
    "\n",
    "X= all_data[:num_train] # 0~num_train -1 행\n",
    "X_test1= all_data[num_train:] # num_train ~ 마지막 행\n",
    "\n",
    "# y_train = train['Survived'].values\n",
    "\n",
    "\n",
    "# ########################################\n",
    "# # 데이터 분할\n",
    "num_train = len(train) # 훈련 데이터 개수\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 나누기\n",
    "#\n",
    "# X= all_data_sprs[:num_train] # 0~num_train -1 행\n",
    "# X_test = all_data_sprs[num_train:] # num_train ~ 마지막 행\n",
    "\n",
    "y = train['Survived'].values\n",
    "\n",
    "\n",
    "X_train , X_valid , y_train, y_valid = train_test_split(X,y, test_size = 0.2, random_state=0)\n",
    "y_test = correct['Survived'].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, \\\n",
    "    StackingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sk_fold = StratifiedKFold(10,shuffle=True, random_state=42)\n",
    "sc =StandardScaler()\n",
    "X_train= sc.fit_transform(X_train)\n",
    "X_train_1= sc.transform(X.values)\n",
    "X_test= sc.transform(X_test)\n",
    "X_submit= sc.transform(X_test1.values)\n",
    "log_reg = LogisticRegression()\n",
    "ran_for  = RandomForestClassifier()\n",
    "ada_boost = AdaBoostClassifier()\n",
    "grad_boost = GradientBoostingClassifier(n_estimators=100)\n",
    "#hist_grad_boost = HistGradientBoostingClassifier()\n",
    "knn = KNeighborsClassifier()\n",
    "tree= DecisionTreeClassifier()\n",
    "svc = SVC()\n",
    "xgb = XGBClassifier()\n",
    "clf = [(\"Logistic Regression\",log_reg,{\"penalty\":['l2'],\"C\":[100, 10, 1.0, 0.1, 0.01]}),\\\n",
    "       (\"Support Vector\",svc,{\"kernel\": [\"rbf\"],\"gamma\":[0.1, 1, 10, 100],\"C\":[0.1, 1, 10, 100, 1000]}),\\\n",
    "       (\"Decision Tree\", tree, {}),\\\n",
    "       (\"Random Forest\",ran_for,{\"n_estimators\":[100],\"random_state\":[42],\"min_samples_leaf\":[5,10,20,40,50],\"bootstrap\":[False]}),\\\n",
    "       (\"Adapative Boost\",ada_boost,{\"n_estimators\":[100],\"learning_rate\":[.6,.8,1]}),\\\n",
    "       (\"Gradient Boost\",grad_boost,{}),\\\n",
    "       #(\"Histogram GB\",hist_grad_boost,{\"loss\":[\"binary_crossentropy\"],\"min_samples_leaf\":[5,10,20,40,50],\"l2_regularization\":[0,.1,1]}),\\\n",
    "       (\"XGBoost\",xgb,{\"n_estimators\":[200],\"max_depth\":[3,4,5],\"learning_rate\":[.01,.1,.2],\"subsample\":[.8],\"colsample_bytree\":[1],\"gamma\":[0,1,5],\"lambda\":[.01,.1,1]}),\\\n",
    "      (\"K Nearest\",knn,{\"n_neighbors\":[3,5,8],\"leaf_size\":[25,30,35]})]\n",
    "stack_list=[]\n",
    "train_scores = pd.DataFrame(columns=[\"Name\",\"Train Score\",\"Test Score\"])\n",
    "i=0\n",
    "for name,clf1,param_grid in clf:\n",
    "    clf = GridSearchCV(clf1,param_grid=param_grid,scoring=\"accuracy\",cv=sk_fold,return_train_score=True)\n",
    "    clf.fit(X_train,y_train.reshape(-1,1))\n",
    "    y_pred = clf.best_estimator_.predict(X_test)\n",
    "    cm = confusion_matrix(y_test,y_pred)\n",
    "    #train_scores.loc[i]= [name,cross_val_score(clf,X_train,y_train,cv=sk_fold,scoring=\"accuracy\").mean(),(cm[0,0]+cm[1,1,])/(cm[0,0]+cm[0,1]+cm[1,0]+cm[1,1])]\n",
    "    train_scores.loc[i]= [name,clf.best_score_,(cm[0,0]+cm[1,1,])/(cm[0,0]+cm[0,1]+cm[1,0]+cm[1,1])]\n",
    "    stack_list.append(clf.best_estimator_)\n",
    "    i=i+1\n",
    "\n",
    "est = [(\"dec_tree\",stack_list[2]),(\"ran_for\",stack_list[3]),(\"ada_boost\",stack_list[4]),(\"grad_boost\",stack_list[5]),(\"hist_grad_boost\",stack_list[6]),(\"svc\",stack_list[1]),(\"lr\",stack_list[0]),(\"knn\",stack_list[8])]\n",
    "sc = StackingClassifier(estimators=est,final_estimator = stack_list[2],cv=sk_fold,passthrough=False)\n",
    "sc.fit(X_train,y_train)\n",
    "y_pred = sc.predict(X_test)\n",
    "cm1 = confusion_matrix(y_test,y_pred)\n",
    "y_pred_train = sc.predict(X_train)\n",
    "cm2 = confusion_matrix(y_train,y_pred_train)\n",
    "train_scores.append(pd.Series([\"Stacking\",(cm2[0,0]+cm2[1,1,])/(cm2[0,0]+cm2[0,1]+cm2[1,0]+cm2[1,1]),(cm1[0,0]+cm1[1,1,])/(cm1[0,0]+cm1[0,1]+cm1[1,0]+cm1[1,1])],index=train_scores.columns),ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ! pip install --upgrade scikit-learn\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_preds = ensemble_predictions\n",
    "\n",
    "y_preds"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# 현재 날짜와 시각 구하기\n",
    "now = datetime.datetime.now()\n",
    "date_list = [now.month, now.day, now.hour, now.minute, now.second]\n",
    "# 현재 날짜와 시각 출력하기\n",
    "print(\"현재 날짜 및 시각 : \", date_list)\n",
    "\n",
    "# 제출 파일 생성\n",
    "\n",
    "submission['Survived'] = y_preds\n",
    "submission.to_csv(f'submission_ensemble2_{date_list[0]}_{date_list[1]}_{date_list[2]}_{date_list[3]}_{date_list[4]}.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 블로그 따라잡기"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_data_2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_data['Family'] = 1 + all_data['SibSp'] + all_data['Parch']\n",
    "\n",
    "all_data['Solo'] = (all_data['Family'] ==1)\n",
    "\n",
    "all_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_data['Name'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "feature = [\n",
    "    'Pclass',\n",
    "    'Sex',\n",
    "    'SibSp',\n",
    "    'Parch',\n",
    "    'Embarked',\n",
    "    'Family',\n",
    "    'Name',\n",
    "    'Solo',\n",
    "    'Age_binned',\n",
    "    'Cabin',\n",
    "    'Fare_clean'\n",
    "]\n",
    "\n",
    "label = [\n",
    "    'Survived',\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#\n",
    "num_train = len(train) # 훈련 데이터 개수\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 나누기\n",
    "\n",
    "X_train= all_data[:num_train] # 0~num_train -1 행\n",
    "X_test = all_data[num_train:] # num_train ~ 마지막 행\n",
    "\n",
    "y_train = train['Survived'].values\n",
    "\n",
    "\n",
    "# ########################################\n",
    "# # 데이터 분할\n",
    "# num_train = len(train) # 훈련 데이터 개수\n",
    "#\n",
    "# # 훈련 데이터와 테스트 데이터 나누기\n",
    "#\n",
    "# X= all_data_sprs[:num_train] # 0~num_train -1 행\n",
    "# X_test = all_data_sprs[num_train:] # num_train ~ 마지막 행\n",
    "#\n",
    "# y = train['Survived'].values\n",
    "#\n",
    "#\n",
    "# X_train , X_valid , y_train, y_valid = train_test_split(X,y, test_size = 0.2, random_state=0)\n",
    "# y_test = submission['Survived'].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train = X_train[feature]\n",
    "target = train[label]\n",
    "\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=50, max_depth=6, random_state=0)\n",
    "cross_val_score(clf, X_train, target, cv=k_fold, scoring='accuracy', ).mean()\n",
    "# Accuracy\n",
    "# 0.8271660424469414"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train = X_train[feature]\n",
    "x_test = X_test[feature]\n",
    "y_train = train[label]\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=50, max_depth=6, random_state=0)\n",
    "clf.fit(x_train, y_train)\n",
    "y_preds = clf.predict(x_test)\n",
    "\n",
    "y_preds"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# 현재 날짜와 시각 구하기\n",
    "now = datetime.datetime.now()\n",
    "date_list = [now.month, now.day, now.hour, now.minute, now.second]\n",
    "# 현재 날짜와 시각 출력하기\n",
    "print(\"현재 날짜 및 시각 : \", date_list)\n",
    "\n",
    "# 제출 파일 생성\n",
    "\n",
    "submission['Survived'] = y_preds\n",
    "submission.to_csv(f'submission_Random_blog_{date_list[0]}_{date_list[1]}_{date_list[2]}_{date_list[3]}_{date_list[4]}.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_data['Survival'] = label_encoder.fit_transform(all_data['Survival'])\n",
    "\n",
    "all_data['Survival']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#\n",
    "num_train = len(train) # 훈련 데이터 개수\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 나누기\n",
    "\n",
    "X= all_data[:num_train] # 0~num_train -1 행\n",
    "X_test1= all_data[num_train:] # num_train ~ 마지막 행\n",
    "\n",
    "# y_train = train['Survived'].values\n",
    "\n",
    "\n",
    "# ########################################\n",
    "# # 데이터 분할\n",
    "num_train = len(train) # 훈련 데이터 개수\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 나누기\n",
    "#\n",
    "# X= all_data_sprs[:num_train] # 0~num_train -1 행\n",
    "# X_test = all_data_sprs[num_train:] # num_train ~ 마지막 행\n",
    "\n",
    "y = train['Survived'].values\n",
    "\n",
    "\n",
    "X_train , X_valid , y_train, y_valid = train_test_split(X,y, test_size = 0.2, random_state=0)\n",
    "y_test = correct['Survived'].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, \\\n",
    "    StackingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sk_fold = StratifiedKFold(10,shuffle=True, random_state=42)\n",
    "sc =StandardScaler()\n",
    "X_train= sc.fit_transform(X_train)\n",
    "X_train_1= sc.transform(X.values)\n",
    "X_test= sc.transform(X_test)\n",
    "X_submit= sc.transform(X_test1.values)\n",
    "log_reg = LogisticRegression()\n",
    "ran_for  = RandomForestClassifier()\n",
    "ada_boost = AdaBoostClassifier()\n",
    "grad_boost = GradientBoostingClassifier(n_estimators=100)\n",
    "#hist_grad_boost = HistGradientBoostingClassifier()\n",
    "knn = KNeighborsClassifier()\n",
    "tree= DecisionTreeClassifier()\n",
    "svc = SVC()\n",
    "xgb = XGBClassifier()\n",
    "clf = [(\"Logistic Regression\",log_reg,{\"penalty\":['l2'],\"C\":[100, 10, 1.0, 0.1, 0.01]}),\\\n",
    "       (\"Support Vector\",svc,{\"kernel\": [\"rbf\"],\"gamma\":[0.1, 1, 10, 100],\"C\":[0.1, 1, 10, 100, 1000]}),\\\n",
    "       (\"Decision Tree\", tree, {}),\\\n",
    "       (\"Random Forest\",ran_for,{\"n_estimators\":[100],\"random_state\":[42],\"min_samples_leaf\":[5,10,20,40,50],\"bootstrap\":[False]}),\\\n",
    "       (\"Adapative Boost\",ada_boost,{\"n_estimators\":[100],\"learning_rate\":[.6,.8,1]}),\\\n",
    "       (\"Gradient Boost\",grad_boost,{}),\\\n",
    "       #(\"Histogram GB\",hist_grad_boost,{\"loss\":[\"binary_crossentropy\"],\"min_samples_leaf\":[5,10,20,40,50],\"l2_regularization\":[0,.1,1]}),\\\n",
    "       (\"XGBoost\",xgb,{\"n_estimators\":[200],\"max_depth\":[3,4,5],\"learning_rate\":[.01,.1,.2],\"subsample\":[.8],\"colsample_bytree\":[1],\"gamma\":[0,1,5],\"lambda\":[.01,.1,1]}),\\\n",
    "      (\"K Nearest\",knn,{\"n_neighbors\":[3,5,8],\"leaf_size\":[25,30,35]})]\n",
    "stack_list=[]\n",
    "train_scores = pd.DataFrame(columns=[\"Name\",\"Train Score\",\"Test Score\"])\n",
    "i=0\n",
    "for name,clf1,param_grid in clf:\n",
    "    clf = GridSearchCV(clf1,param_grid=param_grid,scoring=\"accuracy\",cv=sk_fold,return_train_score=True)\n",
    "    clf.fit(X_train,y_train.reshape(-1,1))\n",
    "    y_pred = clf.best_estimator_.predict(X_test)\n",
    "    cm = confusion_matrix(y_test,y_pred)\n",
    "    #train_scores.loc[i]= [name,cross_val_score(clf,X_train,y_train,cv=sk_fold,scoring=\"accuracy\").mean(),(cm[0,0]+cm[1,1,])/(cm[0,0]+cm[0,1]+cm[1,0]+cm[1,1])]\n",
    "    train_scores.loc[i]= [name,clf.best_score_,(cm[0,0]+cm[1,1,])/(cm[0,0]+cm[0,1]+cm[1,0]+cm[1,1])]\n",
    "    stack_list.append(clf.best_estimator_)\n",
    "    i=i+1\n",
    "\n",
    "est = [(\"dec_tree\",stack_list[2]),(\"ran_for\",stack_list[3]),(\"ada_boost\",stack_list[4]),(\"grad_boost\",stack_list[5]),(\"hist_grad_boost\",stack_list[6]),(\"svc\",stack_list[1]),(\"lr\",stack_list[0]),(\"knn\",stack_list[8])]\n",
    "sc = StackingClassifier(estimators=est,final_estimator = stack_list[2],cv=sk_fold,passthrough=False)\n",
    "sc.fit(X_train,y_train)\n",
    "y_pred = sc.predict(X_test)\n",
    "cm1 = confusion_matrix(y_test,y_pred)\n",
    "y_pred_train = sc.predict(X_train)\n",
    "cm2 = confusion_matrix(y_train,y_pred_train)\n",
    "train_scores.append(pd.Series([\"Stacking\",(cm2[0,0]+cm2[1,1,])/(cm2[0,0]+cm2[0,1]+cm2[1,0]+cm2[1,1]),(cm1[0,0]+cm1[1,1,])/(cm1[0,0]+cm1[0,1]+cm1[1,0]+cm1[1,1])],index=train_scores.columns),ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ! pip install --upgrade scikit-learn\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}